{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNop9WxYy5yYHuWqqoOPFck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch23s020/assignment2/blob/main/Assignment2_partb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyJ1OVyzOe3_"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "0z1VagPVOuXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_img_shape(model_name):\n",
        "\n",
        "    if model_name == 'resnet50':\n",
        "\n",
        "        return 224, 224\n",
        "\n",
        "    elif model_name == 'inception_v3':\n",
        "\n",
        "        return 299, 299\n",
        "\n",
        "    elif model_name == 'inception_resnet_v2':\n",
        "\n",
        "        return 299, 299\n",
        "\n",
        "    elif model_name == 'xception':\n",
        "\n",
        "        return 299, 299\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "\n",
        "def train():\n",
        "    # hyperparameters\n",
        "\n",
        "    project_name = 'cs6910_assignment2_cnn_partb'\n",
        "\n",
        "    model_name = 'resnet50'\n",
        "\n",
        "    epochs = 5\n",
        "\n",
        "    batch_size = 16\n",
        "\n",
        "    optimizer_name = 'Adam'\n",
        "\n",
        "    data_augmentation = False\n",
        "\n",
        "    pretrained = True\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    # Initialize wandb run\n",
        "\n",
        "    wandb.init(project=project_name)\n",
        "\n",
        "    # Data transform according to model\n",
        "\n",
        "    data_transforms = transforms.Compose([\n",
        "\n",
        "        transforms.Resize(load_img_shape(model_name)),\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Loading data\n",
        "    train_data = ImageFolder(root='/content/drive/MyDrive/nature_DL/inaturalist_12K/train', transform=data_transforms)\n",
        "\n",
        "    test_data = ImageFolder(root='/content/drive/MyDrive/nature_DL/inaturalist_12K/val', transform=data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Loading model\n",
        "    model = getattr(models, model_name)(pretrained=pretrained)\n",
        "\n",
        "    num_features = model.fc.in_features\n",
        "\n",
        "    model.fc = nn.Linear(num_features, len(train_data.classes))\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        train_correct, train_loss = .0, .0\n",
        "\n",
        "        for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "\n",
        "            # Get data to device\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Forward_prop\n",
        "            outputs = model(data)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward_prop\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy Calculation\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            train_correct += (predictions == targets).sum().item()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Log metrics to wandb\n",
        "\n",
        "            wandb.log({\n",
        "                'train_loss': loss.item(),\n",
        "\n",
        "                'train_acc': (predictions == targets).float().mean().item(),\n",
        "            })\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        train_acc = train_correct / len(train_data)\n",
        "\n",
        "        # Evaluate on test data\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, targets in test_loader:\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                test_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        test_acc = test_correct / len(test_data)\n",
        "\n",
        "        # Log epoch metrics to wandb\n",
        "\n",
        "        wandb.log({\n",
        "\n",
        "            'epoch': epoch,\n",
        "\n",
        "            'train_acc': train_acc,\n",
        "\n",
        "            'train_loss': train_loss,\n",
        "\n",
        "            'test_acc': test_acc,\n",
        "        })\n",
        "\n",
        "        print(f'\\nEpoch {epoch}, train_acc {train_acc}, train_loss {train_loss}, test_acc {test_acc}')\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "# Call the train function\n",
        "\n",
        "train()\n"
      ],
      "metadata": {
        "id": "f52aaozUOmM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}