{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLVjTAvyY+PdAJMpQZ920b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch23s020/assignment2/blob/main/Assignment2_CH23S020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSzW0_xPFn5G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Mount Google Drive (authentication required only on first run)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify paths\n",
        "zip_path = \"/content/drive/MyDrive/nature_12K.zip\"\n",
        "target_dir = \"/content/drive/MyDrive/Assignment_2\"  # Note the double underscore\n",
        "\n",
        "try:\n",
        "  # Create the target directory (if it doesn't exist)\n",
        "  !mkdir -p {target_dir}\n",
        "\n",
        "  # Extract the zip file\n",
        "  with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_dir)\n",
        "\n",
        "  print(\"Unzipped successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Error unzipping: {e}\")\n",
        "\n",
        "# Unmount Google Drive (optional)\n",
        "#drive.unmount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "0Rrj0Z0gH4E2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729cfbc2-d80c-409b-d6a0-b874928fc713"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.44.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.44.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import wandb\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "ag1BhlgFH4H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Wandb Sweep and Hyperparameter values\n",
        "\n",
        "sweep_config = {\n",
        "\n",
        "    'method': 'random',\n",
        "\n",
        "    'parameters': {\n",
        "\n",
        "        'num_filters': {'values': [[16, 32], [32, 64], [64, 128]]},\n",
        "\n",
        "        'filter_size': {'values': [[3, 3], [5, 5], [7, 7]]},\n",
        "\n",
        "        'activation': {'values': ['ReLU', 'GELU', 'SiLU']},\n",
        "\n",
        "        'use_batchnorm': {'values': [0, 1]},\n",
        "\n",
        "        'use_dropout': {'values': [0, 1]},\n",
        "\n",
        "        'lr': {'values': [0.001, 0.01, 0.1]},\n",
        "\n",
        "        'num_epochs': {'values': [5, 10, 15]},\n",
        "\n",
        "        'filter_org': {'values': ['same', 'different']},\n",
        "\n",
        "        'data_augmentation': {'values': ['yes', 'no']},\n",
        "\n",
        "        'batch_size': {'values': [32, 64, 128]},\n",
        "\n",
        "        'num_neurons': {'values': [64, 128, 256]},\n",
        "\n",
        "        'learning_algorithm': {'values': ['Adam', 'SGD']},\n",
        "\n",
        "        'project': {'values': ['categorized', 'uncategorized']}\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Assignment2_CNN\")\n",
        "\n",
        "#training function\n",
        "\n",
        "def train_sweep():\n",
        "\n",
        "    # Initialize Wandb with project name\n",
        "    wandb.init()\n",
        "\n",
        "    # Specify the sweep configuration\n",
        "    config_default = wandb.config\n",
        "\n",
        "    # Start training with the current configuration\n",
        "\n",
        "    for _ in range(config_default['num_epochs']):\n",
        "        train(config_default)\n",
        "\n",
        "    # Finish the Wandb run after completing all epochs to avoid broken pipe error\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "def train(config):\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Data augmentation and normalization Step\n",
        "\n",
        "    if config['data_augmentation'] == 'yes':\n",
        "\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "            transforms.ToTensor(),\n",
        "\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    else:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "\n",
        "            transforms.CenterCrop(224),\n",
        "\n",
        "            transforms.ToTensor(),\n",
        "\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "\n",
        "        transforms.Resize(256),\n",
        "\n",
        "        transforms.CenterCrop(224),\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Data Loading and Pre-Processing Step (Using the data directly from google drive)\n",
        "    train_data = datasets.ImageFolder(root='/content/drive/MyDrive/inaturalist_12K/train', transform=train_transforms)\n",
        "\n",
        "    test_data = datasets.ImageFolder(root='/content/drive/MyDrive/inaturalist_12K/val', transform=test_transforms)\n",
        "\n",
        "    # Split train_data into train and validation\n",
        "\n",
        "    train_size = int(0.8 * len(train_data))\n",
        "\n",
        "    val_size = len(train_data) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n",
        "\n",
        "    # DataLoader with multiprocessing adding num_worker = 2\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
        "\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "#Step3: Class and Training Loop\n",
        "\n",
        "    class CNN(nn.Module):\n",
        "\n",
        "        def __init__(self, num_classes, num_filters, filter_size, activation, filter_org, use_batchnorm, use_dropout, num_neurons):\n",
        "\n",
        "            super(CNN, self).__init__()\n",
        "\n",
        "            self.num_classes = num_classes\n",
        "\n",
        "            self.num_filters = num_filters\n",
        "\n",
        "            self.filter_size = filter_size\n",
        "\n",
        "            self.activation = activation\n",
        "\n",
        "            self.filter_org = filter_org\n",
        "\n",
        "            self.use_batchnorm = use_batchnorm\n",
        "\n",
        "            self.use_dropout = use_dropout\n",
        "\n",
        "            self.num_neurons = num_neurons\n",
        "\n",
        "            # Convolution layers\n",
        "\n",
        "            layers = []\n",
        "\n",
        "            in_channels = 3 # Assuming RGB images\n",
        "\n",
        "            prev_output_size = 224  # Initial image size, adjust as necessary\n",
        "\n",
        "            for i in range(len(num_filters)):\n",
        "\n",
        "                layers.append(nn.Conv2d(in_channels, num_filters[i], filter_size[i]))\n",
        "\n",
        "                if use_batchnorm:\n",
        "\n",
        "                    layers.append(nn.BatchNorm2d(num_filters[i]))\n",
        "\n",
        "                if activation == 'ReLU':\n",
        "\n",
        "                    layers.append(nn.ReLU())\n",
        "\n",
        "                elif activation == 'GELU':\n",
        "\n",
        "                    layers.append(nn.GELU())\n",
        "\n",
        "                elif activation == 'SiLU':\n",
        "\n",
        "                    layers.append(nn.SiLU())\n",
        "\n",
        "                elif activation == 'Mish':\n",
        "\n",
        "                    layers.append(nn.Mish())\n",
        "                layers.append(nn.MaxPool2d(2, 2))\n",
        "\n",
        "                if use_dropout:\n",
        "\n",
        "                    layers.append(nn.Dropout(0.2))\n",
        "\n",
        "                in_channels = num_filters[i]\n",
        "\n",
        "                # Calculate the output size of this layer\n",
        "                prev_output_size = (prev_output_size - filter_size[i] + 1) // 2\n",
        "\n",
        "            self.conv_layers = nn.Sequential(*layers)\n",
        "\n",
        "            # Calculate the input size to the fully connected layers\n",
        "            self.fc_input_size = in_channels * prev_output_size * prev_output_size\n",
        "\n",
        "            # Dense layers\n",
        "            self.fc = nn.Linear(self.fc_input_size, num_neurons)\n",
        "\n",
        "            self.fc2 = nn.Linear(num_neurons, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "\n",
        "            x = self.conv_layers(x)\n",
        "\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "            x = self.fc(x)\n",
        "\n",
        "            x = self.fc2(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Initialize the model\n",
        "\n",
        "    model = CNN(num_classes=10, num_filters=config['num_filters'], filter_size=config['filter_size'],\n",
        "\n",
        "                activation=config['activation'], filter_org=config['filter_org'],\n",
        "\n",
        "                use_batchnorm=config['use_batchnorm'], use_dropout=config['use_dropout'],\n",
        "\n",
        "                num_neurons=config['num_neurons']).to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if config['learning_algorithm'] == 'Adam':\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "\n",
        "    elif config['learning_algorithm'] == 'SGD':\n",
        "\n",
        "        optimizer = optim.SGD(model.parameters(), lr=config['lr'])\n",
        "\n",
        "    # Training loop\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "       # Use num_epochs from config\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        correct_train = 0\n",
        "\n",
        "        total_train = 0\n",
        "\n",
        "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "\n",
        "            data, targets = data.to(device), targets.to(device)  # Move data to device\n",
        "\n",
        "            # Forward_Prop\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward_prop\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculating training accuracy\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total_train += targets.size(0)\n",
        "\n",
        "            correct_train += (predicted == targets).sum().item()\n",
        "\n",
        "            # Printing training accuracy after each batch\n",
        "\n",
        "            train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{config[\"num_epochs\"]}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Train Acc: {train_accuracy:.2f}%')\n",
        "\n",
        "        # Log training loss and accuracy\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        wandb.log({'train_loss': train_loss, 'train_accuracy': train_accuracy}, step=epoch)\n",
        "\n",
        "        # Validation loop\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            correct_val = 0\n",
        "\n",
        "            total_val = 0\n",
        "\n",
        "            val_loss = 0.0\n",
        "\n",
        "            for data, targets in val_loader:\n",
        "\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                  # Move data to device\n",
        "\n",
        "                outputs = model(data)\n",
        "\n",
        "                val_loss += criterion(outputs, targets).item()\n",
        "\n",
        "                # Calculating validation accuracy\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                total_val += targets.size(0)\n",
        "\n",
        "                correct_val += (predicted == targets).sum().item()\n",
        "\n",
        "            val_accuracy = 100 * correct_val / total_val\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{config[\"num_epochs\"]}], Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "            # Log validation loss\n",
        "            wandb.log({'val_loss': val_loss/len(val_loader)}, step=epoch)\n",
        "\n",
        "            # Log metrics to Wandb\n",
        "            wandb.log({'val_accuracy': val_accuracy})\n",
        "\n",
        "            # # Log parallel coordinate plot\n",
        "\n",
        "            # num_samples = min(len(train_data), 1000)\n",
        "\n",
        "            # indices = torch.randperm(len(train_data))[:num_samples]\n",
        "\n",
        "            # train_subset = torch.utils.data.Subset(train_data, indices)\n",
        "\n",
        "            # dataloader = torch.utils.data.DataLoader(train_subset, batch_size=num_samples)\n",
        "\n",
        "            # images, labels = next(iter(dataloader))\n",
        "\n",
        "            # images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # model.eval()\n",
        "\n",
        "            # outputs = model(images)\n",
        "\n",
        "            # _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # df = pd.DataFrame({\n",
        "            #     'Label': labels.cpu().numpy(),\n",
        "            #     'Prediction': preds.cpu().numpy()\n",
        "            # })\n",
        "            # wandb.log({\"parallel_coordinate_plot\": wandb.plot.parallel_coordinates(df, 'Label')}, step=epoch)\n",
        "\n",
        "            # # Log correlation plot\n",
        "            # corr_matrix = np.corrcoef(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "\n",
        "            # wandb.log({\"correlation_plot\": wandb.plot.correlation_matrix(corr_matrix)}, step=epoch)\n",
        "\n",
        "# Run the sweep\n",
        "wandb.agent(sweep_id, function=train_sweep)\n"
      ],
      "metadata": {
        "id": "TL6pcSdUH-RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uMbLueAUbCny"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbvp1IjhIoSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}